{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honeybeat1/wanted_pre_onboarding/blob/main/daily-assignment/week2/%5Binfer%5D%EC%A0%95%EB%8B%A4%ED%98%84_Week2_4_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592U6lXs3d2t"
      },
      "source": [
        "# Week2_4 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 커스텀 모듈(`helper.py`)에서 **클래스와 함수를 임포트**할 수 있다.\n",
        "- **autograd**의 개념 복습\n",
        "\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- train() 함수에 **epoch, scheduler, grad_clipping**을 추가할 수 있다.\n",
        "- **validate() 함수를 구현**할 수 있다.\n",
        "\n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- train() 함수를 사용해 데이터를 **4 epoch 학습**할 수 있다. \n",
        "- **predict 함수를 구현**할 수 있다. \n",
        "- **evaluation metric 구현**할 수 있다. \n",
        "    - accuracy\n",
        "\n",
        "\n",
        "\n",
        "### Reference\n",
        "- [Pytorch Autograd Explain official document](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.370876Z",
          "start_time": "2022-02-02T04:01:46.520392Z"
        },
        "id": "KSX-wQA1RD1h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.375658Z",
          "start_time": "2022-02-02T04:01:47.372242Z"
        },
        "id": "MH7RJjtZXOHf"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "seed = 7777\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:07:00.849353Z",
          "start_time": "2022-01-31T13:06:56.187962Z"
        },
        "id": "62plMahMWr0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3b7348-929d-44fa-d2b2-d5b960000fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WagJcj-Ud4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e24daf-0d50-49f3-af8b-4770659eda8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnETqIqdVApF"
      },
      "outputs": [],
      "source": [
        "# 어제 자신이 구현한 helper.py 모듈 경로를 입력\n",
        "sys.path.append('/content/drive/MyDrive/data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/data\")"
      ],
      "metadata": {
        "id": "ZnVp9pYpmssa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.735578Z",
          "start_time": "2022-02-02T04:01:49.475969Z"
        },
        "id": "N84mZeYMUFxJ"
      },
      "outputs": [],
      "source": [
        "# helper 모듈을 import하면 이전에 구현했던 다양한 함수 및 클래스를 사용할 수 있음 \n",
        "# 함수: set_device()\n",
        "# 함수: custom_collate_fn() \n",
        "# 클래스: CustomDataset\n",
        "# 클래스: CustomClassifier\n",
        "# 가 import 됨\n",
        "\n",
        "from helper import *\n",
        "from torch.utils.data import RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.771743Z",
          "start_time": "2022-02-02T04:01:49.736866Z"
        },
        "id": "oR5EWmh5UFxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0be97ec-6804-49ac-88ff-5f4885046958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# device\n",
        "device = set_device()\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkNxrCV45Q3m"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YBUQykS5Q3n"
      },
      "source": [
        "### 모듈에서 클래스와 함수를 임포트해 다음을 구현\n",
        "- train_dataset, train_dataloader\n",
        "- valid_dataset, valid_dataloader\n",
        "- test_dataset, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv"
      ],
      "metadata": {
        "id": "cjNksUEwGACb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d781e2-35a4-4363-fa05-dcb27b8039da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-24 15:48:55--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971625 (949K) [text/plain]\n",
            "Saving to: ‘sample_df.csv’\n",
            "\n",
            "\rsample_df.csv         0%[                    ]       0  --.-KB/s               \rsample_df.csv       100%[===================>] 948.85K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-24 15:48:55 (24.1 MB/s) - ‘sample_df.csv’ saved [971625/971625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv"
      ],
      "metadata": {
        "id": "kXfk8ZEHGB0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888bc045-645d-4163-c5b7-fbfbc1ba6889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-24 15:48:56--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101383 (99K) [text/plain]\n",
            "Saving to: ‘sample_df_test.csv’\n",
            "\n",
            "sample_df_test.csv  100%[===================>]  99.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-03-24 15:48:56 (8.30 MB/s) - ‘sample_df_test.csv’ saved [101383/101383]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.037044Z",
          "start_time": "2022-02-02T04:01:52.707669Z"
        },
        "id": "KVo5dPnmUFxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5cf9b3-9ffe-4929-fa31-27b6f1a61c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape : (10000, 3)\n",
            "test shape : (1000, 3)\n"
          ]
        }
      ],
      "source": [
        "# 학습 & 평가 데이터셋 로드\n",
        "# 학습 및 평가 샘플 데이터 개수는 각각 10,000개, 1,000개\n",
        "\n",
        "df_train = pd.read_csv('sample_df.csv')\n",
        "df_test = pd.read_csv('sample_df_test.csv')\n",
        "\n",
        "print(f\"train shape : {df_train.shape}\")\n",
        "print(f\"test shape : {df_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ooICH_l3eyEQ",
        "outputId": "85afd09e-15df-476a-8b09-955db26c2b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           document  label\n",
              "0  8525343  나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.      0\n",
              "1  4572888                현암이 소지섭이었으면 좋았겠는데..스토리각색도 좀 깔끔하게...      0\n",
              "2  8504845                                      ㅎㅎㅎ 대단하네 ㅜ,.ㅡ      0\n",
              "3  5003367                            이거보고 돈날린 기억이...........      0\n",
              "4  3015049                                  한국영화 어쩌다 이지경까지 ㅠㅠ      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12609fd8-9256-4ec0-8e2c-87c4f7934668\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8525343</td>\n",
              "      <td>나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4572888</td>\n",
              "      <td>현암이 소지섭이었으면 좋았겠는데..스토리각색도 좀 깔끔하게...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8504845</td>\n",
              "      <td>ㅎㅎㅎ 대단하네 ㅜ,.ㅡ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5003367</td>\n",
              "      <td>이거보고 돈날린 기억이...........</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3015049</td>\n",
              "      <td>한국영화 어쩌다 이지경까지 ㅠㅠ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12609fd8-9256-4ec0-8e2c-87c4f7934668')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12609fd8-9256-4ec0-8e2c-87c4f7934668 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12609fd8-9256-4ec0-8e2c-87c4f7934668');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_train.document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hotYVwmenn_t",
        "outputId": "afa68e4d-61a0-4fd6-9a1b-0b43effcf19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.085720Z",
          "start_time": "2022-02-02T04:01:53.081413Z"
        },
        "id": "Ql82Ew2VUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc75e548-2481-471b-ec4f-06c97a26b241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10000\n",
            "Train Dataset 1st element: ('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)\n",
            "Test Dataset len: 1000\n",
            "Test Dataset 1st element: ('신용문객잔 보고 후속편인줄 알고 봤더만 완전 개판이네 18.. 이련결 그냥 절에나 쳐 들어 가라.. 회오리에서 싸우는 신 참 가관이더라 .. 서극도 완전 쓰레기 감독이 다 됐구나.. 액션도 쓰레기고 배우들 연기도 참 가관이더라 18', 0)\n"
          ]
        }
      ],
      "source": [
        "# Dataset 구현\n",
        "# helper.py에 있는 CustomDataset 활용하여 train datset, test dataset 만들기\n",
        "\n",
        "train_dataset = CustomDataset(df_train.document.to_list(), df_train.label.to_list())\n",
        "test_dataset = CustomDataset(df_test.document.to_list(), df_test.label.to_list())\n",
        "\n",
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n",
        "\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")\n",
        "print(f\"Test Dataset 1st element: {test_dataset[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "5CvLyLeifJSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.152070Z",
          "start_time": "2022-02-02T04:01:53.145410Z"
        },
        "id": "7WUY6h8WUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d7b1a6-4153-4bee-f788-fd2559b9eae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset len: 9000\n",
            "Valid dataset len: 1000\n"
          ]
        }
      ],
      "source": [
        "# Train Dataset을 학습과 검증 셋으로 분리\n",
        "# 학습 셋과 검증 셋의 비율은 9:1\n",
        "# torch.utils.data에서 제공되는 데이터 세트를 임의로 분할할 수 있는 함수 찾아서 사용 << random_split\n",
        "n_train_sample = df_train.shape[0]\n",
        "\n",
        "n_train = int(n_train_sample*0.9)\n",
        "n_valid = n_train_sample - n_train \n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid])\n",
        "\n",
        "print(f\"Train dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset len: {len(valid_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.268838Z",
          "start_time": "2022-02-02T04:01:53.263780Z"
        },
        "id": "H5nc7SpTUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb08bce-192a-48d8-ac2d-01f799eadde8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 282\n",
            "Valid dataloader # steps: 16\n",
            "Test dataloader # steps: 16\n"
          ]
        }
      ],
      "source": [
        "# DataLoader 구현\n",
        "# train과 validation의 batch size는 각각 32, 64로 설정\n",
        "# test의 batch size는 validation과 동일\n",
        "# train에 사용할 DataLoader에서는 sampler로 RandomSampler 사용\n",
        "# validation과 test에 사용할 DataLoader에서는 sampler로 SequentialSampler 사용\n",
        "# 모든 DataLoader의 collate_fn은 helper.py에 있는 custom_collate_fn 사용\n",
        "\n",
        "train_batch_size = 32\n",
        "valid_batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=train_batch_size, \n",
        "    sampler=RandomSampler(train_dataset), \n",
        "    collate_fn=custom_collate_fn)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=valid_batch_size, \n",
        "    sampler=SequentialSampler(valid_dataset), \n",
        "    collate_fn=custom_collate_fn)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=valid_batch_size, \n",
        "    sampler=SequentialSampler(test_dataset), \n",
        "    collate_fn=custom_collate_fn)\n",
        "\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kEgqvBIUFxN"
      },
      "source": [
        "### `auto_grad` 개념 복습\n",
        "- torch의 `auto_grad` 기능\n",
        "    - pytorch는 `requires_grad` 파리미터의 값이 True인 텐서에 한해서 미분값을 자동으로 계산한다.\n",
        "    - 미분값은 `loss.backward()` 가 호출될 때 자동으로 계산된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:23.502936Z",
          "start_time": "2022-01-31T13:45:20.029987Z"
        },
        "id": "oYjYpQ1DUFxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f317e8c9-c327-4965-a4d7-ec712147b92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# helper.py에 있는 CustomClassifier 모델을 로드해 model_freeze 변수에 instance를 생성\n",
        "# hidden_size=768\n",
        "# n_label=2\n",
        "# freeze_base=True\n",
        "\n",
        "model_freeze = CustomClassifier(hidden_size=768, n_label=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:34.604914Z",
          "start_time": "2022-01-31T13:45:34.586711Z"
        },
        "id": "XxNFh8KZUFxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67799206-1f7f-4fbe-bf1a-130f3809b4c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['bert.embeddings.position_ids', 'bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# model_freeze 모델의 모든 파라미터를 출력해보고 아래 질문에 답해 보자\n",
        "\n",
        "model_freeze.state_dict().keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_freeze.named_parameters():\n",
        "    print(name, param.size(), param.requires_grad)"
      ],
      "metadata": {
        "id": "NmIbo2lPq5BC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99707edb-b0f4-48e2-d2d2-e1714cb8ad1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight torch.Size([32000, 768]) True\n",
            "bert.embeddings.position_embeddings.weight torch.Size([512, 768]) True\n",
            "bert.embeddings.token_type_embeddings.weight torch.Size([2, 768]) True\n",
            "bert.embeddings.LayerNorm.weight torch.Size([768]) True\n",
            "bert.embeddings.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.0.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.0.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.0.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.0.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.1.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.1.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.1.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.1.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.2.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.2.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.2.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.2.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.3.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.3.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.3.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.3.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.4.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.4.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.4.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.4.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.5.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.5.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.5.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.5.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.6.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.6.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.6.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.6.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.7.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.7.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.7.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.7.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.8.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.8.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.8.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.8.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.9.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.9.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.9.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.9.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.10.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.10.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.10.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.10.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.11.attention.self.query.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.11.attention.self.key.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.11.attention.self.value.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768]) True\n",
            "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768]) True\n",
            "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072]) True\n",
            "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072]) True\n",
            "bert.encoder.layer.11.output.dense.bias torch.Size([768]) True\n",
            "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768]) True\n",
            "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768]) True\n",
            "bert.pooler.dense.weight torch.Size([768, 768]) True\n",
            "bert.pooler.dense.bias torch.Size([768]) True\n",
            "classifier.0.weight torch.Size([32, 768]) True\n",
            "classifier.0.bias torch.Size([32]) True\n",
            "classifier.3.weight torch.Size([2, 32]) True\n",
            "classifier.3.bias torch.Size([2]) True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_freeze.named_parameters():\n",
        "  if name == 'classifier.0.weight':\n",
        "    print(name, param.size(), param.requires_grad)\n",
        "    print(param.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPWZg94MsqB_",
        "outputId": "1bcbd82b-cae0-4b1e-f78e-fd10d08fe03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.0.weight torch.Size([32, 768]) True\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KloNNAKI5Q3r"
      },
      "source": [
        "### `auto_grad` 개념 및 모델 구조 복습을 위해 다음 항목에 답해 보자\n",
        "- `bert.encoder.layer.0.attention.self.query.weight` 텐서의 gradient는 True인 상태인가?\n",
        "> Yes\n",
        "- `classifier.0.weight` 텐서의 shape은? \n",
        "> torch.Size([32, 768])\n",
        "- `classifier.0.weight` 텐서는 freeze 상태인가 ? \n",
        "> No\n",
        "- `classifier.0.weight` 텐서의 gradient 값은 무엇인가? \n",
        "> None\n",
        "\n",
        "원래라면 model.backward()를 호출하여 자동 계산된 미분 값을 param.grad 메소드로 구할 수 있으나 \n",
        "model_freeze 모델에 input 값이 없으므로 계산이 안됨. \n",
        "따라서 현재는 None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iIrHg1xUFxP"
      },
      "source": [
        "### 위 모델 (`model_freeze`)의 모든 파라미터의 gradient를 freeze 해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:49:26.820569Z",
          "start_time": "2022-01-31T13:49:26.816511Z"
        },
        "id": "sHkaFgC8UFxP"
      },
      "outputs": [],
      "source": [
        "# 모든 파라미터의 gradient를 freeze 해보고 제대로 변경되었는지 \b확인하기 위해 모델의 모든 파라미터를 출력해보자.\n",
        "\n",
        "for param in model_freeze.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_freeze.named_parameters():\n",
        "    print(name, param.size(), param.requires_grad)"
      ],
      "metadata": {
        "id": "NY2toH1EtdwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4936d1-cf1f-4d50-a150-d93398a5dcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight torch.Size([32000, 768]) False\n",
            "bert.embeddings.position_embeddings.weight torch.Size([512, 768]) False\n",
            "bert.embeddings.token_type_embeddings.weight torch.Size([2, 768]) False\n",
            "bert.embeddings.LayerNorm.weight torch.Size([768]) False\n",
            "bert.embeddings.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.0.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.0.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.0.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.0.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.1.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.1.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.1.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.1.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.2.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.2.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.2.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.2.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.3.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.3.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.3.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.3.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.4.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.4.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.4.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.4.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.5.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.5.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.5.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.5.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.6.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.6.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.6.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.6.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.7.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.7.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.7.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.7.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.8.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.8.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.8.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.8.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.9.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.9.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.9.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.9.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.10.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.10.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.10.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.10.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.11.attention.self.query.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.11.attention.self.key.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.11.attention.self.value.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072]) False\n",
            "bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072]) False\n",
            "bert.encoder.layer.11.output.dense.bias torch.Size([768]) False\n",
            "bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768]) False\n",
            "bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768]) False\n",
            "bert.pooler.dense.weight torch.Size([768, 768]) False\n",
            "bert.pooler.dense.bias torch.Size([768]) False\n",
            "classifier.0.weight torch.Size([32, 768]) False\n",
            "classifier.0.bias torch.Size([32]) False\n",
            "classifier.3.weight torch.Size([2, 32]) False\n",
            "classifier.3.bias torch.Size([2]) False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsMgM3sK5Q3t"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUn-6PFP5Q3t"
      },
      "source": [
        "### `scheduler` 를 생성 \n",
        "- 스케쥴러를 알기 전에 먼저 `epoch`의 개념을 알아야 한다. Epoch는 dataset를 **몇 번 반복**해 학습할 것인지를 의미한다. 만약 dataset의 개수가 2,000개이고 epoch을 2번 학습하게 되면 총 4,000개의 데이터를 학습하게 된다.   \n",
        "- 스케쥴러는 epoch에 따라 learning rate의 값을 조정하는 것을 의미한다. \n",
        "- 예를 들어 [여기](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)의 그림에서 볼 수 있듯이 `get_linear_schedule_with_warmup`는 특정 step까지는 learning rate를 천천히 상승시키다가 고점에 도달하면 다시 하락시킨다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FuADvuT5Q3t"
      },
      "source": [
        "### `model`, `optimizer`, `scheduler`를 초기화(=인스턴스 생성)하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.217735Z",
          "start_time": "2022-02-02T04:01:59.210482Z"
        },
        "id": "-sE7xjYcRD1p"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.549660Z",
          "start_time": "2022-02-02T04:01:59.545752Z"
        },
        "id": "2eTFXzy8VK9R"
      },
      "outputs": [],
      "source": [
        "# model:CustomClassifier 사용, hidden size는 768, label 개수는 2\n",
        "# optimizer: AdamW 사용, learning rate는 2e-5\n",
        "# scheduler: transformers.get_linear_schedule_with_warmup 함수 사용, 단, num_warmup_steps 매개 변수는 사용하지 않음\n",
        "\n",
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러를 초기화한 후 반환\n",
        "    \"\"\"\n",
        "    \n",
        "    model = CustomClassifier(hidden_size=768, n_label=2)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(), #update 대상 파라미터 입력\n",
        "        lr = 2e-5,\n",
        "        eps=1e-8\n",
        "    )\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, # 여기서는 warmup 사용하지 않음\n",
        "        num_training_steps=total_steps)\n",
        "\n",
        "    return model, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-8_5as5Q3u"
      },
      "source": [
        "### model, optimizer, scheduler의 파라미터 저장하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:02.786877Z",
          "start_time": "2022-02-02T04:02:02.783726Z"
        },
        "id": "vIP1BjFA5Q3u"
      },
      "outputs": [],
      "source": [
        "# 모델 저장 함수 구현\n",
        "\n",
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'{path}/model.ckpt.{epoch}'\n",
        "    \n",
        "    # torch.save 함수 참고\n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss' : loss\n",
        "        }, \n",
        "        file_name\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3BUrgtJ5Q3v"
      },
      "source": [
        "### `validate()` 함수 구현 \n",
        "- `validate()` 함수 내 model의 상태는 **evaluate**이어야 한다. evaluate 상태의 model은 dropout을 진행하지 않는다. \n",
        "- **forward**를 진행할 때 `with torch.no_grad(): ...` 설정해 미분 계산을 방지한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:11.636684Z",
          "start_time": "2022-02-02T04:02:11.631550Z"
        },
        "id": "VHpuV0CXUFxR"
      },
      "outputs": [],
      "source": [
        "# input: model, valid_dataloader\n",
        "# output: loss, 정확도\n",
        "\n",
        "def validate(model, valid_dataloader):\n",
        "  global loss_fct\n",
        "  # 모델을 evaluate 모드로 설정 & device 할당\n",
        "  model.eval()\n",
        "  model.to(device)\n",
        "  \n",
        "  total_loss, total_acc= 0,0\n",
        "        \n",
        "  for step, batch in enumerate(valid_dataloader):\n",
        "      \n",
        "      # tensor 연산 전, 각 tensor에 device 할당\n",
        "      batch = tuple(item.to(device) for item in batch)\n",
        "          \n",
        "      batch_input, batch_label = batch\n",
        "          \n",
        "      # gradient 계산하지 않고 forward 진행\n",
        "      with torch.no_grad():\n",
        "          logits = model(**batch_input)\n",
        "          \n",
        "      # loss\n",
        "      loss = loss_fct(logits, batch_label)\n",
        "      total_loss += loss.item()\n",
        "      \n",
        "      # accuracy\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      preds = torch.argmax(probs, dim=1).flatten()\n",
        "      acc = (preds == batch_label).cpu().numpy().mean()\n",
        "      total_acc+=acc\n",
        "  \n",
        "  total_loss = total_loss/(step+1)\n",
        "  total_acc = total_acc/(step+1)*100\n",
        "\n",
        "  return total_loss, total_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NukaJc15UFxQ"
      },
      "source": [
        "### `train()` 함수에 `epoch`와 `clip_grad_norm` 추가\n",
        "- data_loader를 `epoch`만큼 반복하면서 학습하도록 `train()` 함수를 수정하라\n",
        "- `gradient cliping`은 미분 값 너무 큰 경우 gradient exploding되는 현상을 막기 위해 미분값이 `threshold`를 넘을 경우 특정 비율을 미분 값에 곱해 크기를 줄여준다.\n",
        "- Reference\n",
        "  - [clip_grad_norm_ official document](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "  - [그래디언트 클립핑 설명 한국어 블로그](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-6/05-gradient-clipping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:10.624280Z",
          "start_time": "2022-02-02T04:02:10.615781Z"
        },
        "id": "ZvY5rxDKHQAp"
      },
      "outputs": [],
      "source": [
        "# 위에서 구현한 모델 저장 함수(save_checkpoint)와 validate 함수도 추가해보자\n",
        "\n",
        "loss_fct = CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_dataloader, valid_dataloader=valid_dataloader, epochs=2):\n",
        "        global scheduler, loss_fct\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 (max_norm = 1)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "                \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "\n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "\n",
        "\n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "            \n",
        "            # checkpoint 저장\n",
        "            save_checkpoint(path, model, optimizer, scheduler, epoch, loss)\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '.'"
      ],
      "metadata": {
        "id": "qEXHY3_ZGstc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NWKzxIaf1QJ"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFWnii7a5Q3w"
      },
      "source": [
        "### 학습 데이터를 epoch 4까지 학습\n",
        "- 매 epoch마다 다음을 수행한다.\n",
        "  - 학습이 끝난 후 validate() 함수 실행 \n",
        "  - validate() 함수가 끝난 후 model save 함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:02:11.377612Z",
          "start_time": "2022-02-02T04:02:20.931961Z"
        },
        "id": "7Er1qKtsf1QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "554ac15b-13da-4bde-b494-578453d95663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 4 epochs: 1128\n",
            "*****Epoch 0 Train Start*****\n",
            "Epoch: 0, Step : 10, LR : 1.9804964539007094e-05, Avg Loss : 0.6934\n",
            "Epoch: 0, Step : 20, LR : 1.962765957446809e-05, Avg Loss : 0.6344\n",
            "Epoch: 0, Step : 30, LR : 1.945035460992908e-05, Avg Loss : 0.5780\n",
            "Epoch: 0, Step : 40, LR : 1.927304964539007e-05, Avg Loss : 0.5382\n",
            "Epoch: 0, Step : 50, LR : 1.9095744680851064e-05, Avg Loss : 0.5233\n",
            "Epoch: 0, Step : 60, LR : 1.891843971631206e-05, Avg Loss : 0.4685\n",
            "Epoch: 0, Step : 70, LR : 1.8741134751773053e-05, Avg Loss : 0.4277\n",
            "Epoch: 0, Step : 80, LR : 1.8563829787234043e-05, Avg Loss : 0.4295\n",
            "Epoch: 0, Step : 90, LR : 1.8386524822695038e-05, Avg Loss : 0.4216\n",
            "Epoch: 0, Step : 100, LR : 1.8209219858156032e-05, Avg Loss : 0.4513\n",
            "Epoch: 0, Step : 110, LR : 1.8031914893617023e-05, Avg Loss : 0.3996\n",
            "Epoch: 0, Step : 120, LR : 1.7854609929078013e-05, Avg Loss : 0.3905\n",
            "Epoch: 0, Step : 130, LR : 1.7677304964539008e-05, Avg Loss : 0.3686\n",
            "Epoch: 0, Step : 140, LR : 1.7500000000000002e-05, Avg Loss : 0.3846\n",
            "Epoch: 0, Step : 150, LR : 1.7322695035460996e-05, Avg Loss : 0.3966\n",
            "Epoch: 0, Step : 160, LR : 1.7145390070921987e-05, Avg Loss : 0.3626\n",
            "Epoch: 0, Step : 170, LR : 1.696808510638298e-05, Avg Loss : 0.3227\n",
            "Epoch: 0, Step : 180, LR : 1.6790780141843972e-05, Avg Loss : 0.3301\n",
            "Epoch: 0, Step : 190, LR : 1.6613475177304966e-05, Avg Loss : 0.3893\n",
            "Epoch: 0, Step : 200, LR : 1.6436170212765957e-05, Avg Loss : 0.3523\n",
            "Epoch: 0, Step : 210, LR : 1.625886524822695e-05, Avg Loss : 0.3483\n",
            "Epoch: 0, Step : 220, LR : 1.6081560283687945e-05, Avg Loss : 0.3791\n",
            "Epoch: 0, Step : 230, LR : 1.590425531914894e-05, Avg Loss : 0.3525\n",
            "Epoch: 0, Step : 240, LR : 1.572695035460993e-05, Avg Loss : 0.3456\n",
            "Epoch: 0, Step : 250, LR : 1.5549645390070924e-05, Avg Loss : 0.4092\n",
            "Epoch: 0, Step : 260, LR : 1.5372340425531915e-05, Avg Loss : 0.3809\n",
            "Epoch: 0, Step : 270, LR : 1.5195035460992908e-05, Avg Loss : 0.3110\n",
            "Epoch: 0, Step : 280, LR : 1.5017730496453902e-05, Avg Loss : 0.3291\n",
            "Epoch 0 Total Mean Loss : 0.4194\n",
            "*****Epoch 0 Train Finish*****\n",
            "\n",
            "*****Epoch 0 Valid Start*****\n",
            "Epoch 0 Valid Loss : 0.2835 Valid Acc : 88.63\n",
            "*****Epoch 0 Valid Finish*****\n",
            "\n",
            "Saving epoch 0 checkpoint at ./model.ckpt.0\n",
            "*****Epoch 1 Train Start*****\n",
            "Epoch: 1, Step : 10, LR : 1.4804964539007095e-05, Avg Loss : 0.2737\n",
            "Epoch: 1, Step : 20, LR : 1.4627659574468087e-05, Avg Loss : 0.3237\n",
            "Epoch: 1, Step : 30, LR : 1.4450354609929078e-05, Avg Loss : 0.2160\n",
            "Epoch: 1, Step : 40, LR : 1.427304964539007e-05, Avg Loss : 0.2643\n",
            "Epoch: 1, Step : 50, LR : 1.4095744680851065e-05, Avg Loss : 0.2526\n",
            "Epoch: 1, Step : 60, LR : 1.3918439716312057e-05, Avg Loss : 0.2081\n",
            "Epoch: 1, Step : 70, LR : 1.3741134751773051e-05, Avg Loss : 0.2663\n",
            "Epoch: 1, Step : 80, LR : 1.3563829787234044e-05, Avg Loss : 0.2077\n",
            "Epoch: 1, Step : 90, LR : 1.3386524822695038e-05, Avg Loss : 0.3305\n",
            "Epoch: 1, Step : 100, LR : 1.320921985815603e-05, Avg Loss : 0.2621\n",
            "Epoch: 1, Step : 110, LR : 1.3031914893617021e-05, Avg Loss : 0.2460\n",
            "Epoch: 1, Step : 120, LR : 1.2854609929078014e-05, Avg Loss : 0.3214\n",
            "Epoch: 1, Step : 130, LR : 1.2677304964539008e-05, Avg Loss : 0.2622\n",
            "Epoch: 1, Step : 140, LR : 1.25e-05, Avg Loss : 0.2845\n",
            "Epoch: 1, Step : 150, LR : 1.2322695035460995e-05, Avg Loss : 0.2715\n",
            "Epoch: 1, Step : 160, LR : 1.2145390070921987e-05, Avg Loss : 0.2108\n",
            "Epoch: 1, Step : 170, LR : 1.196808510638298e-05, Avg Loss : 0.2338\n",
            "Epoch: 1, Step : 180, LR : 1.1790780141843972e-05, Avg Loss : 0.2148\n",
            "Epoch: 1, Step : 190, LR : 1.1613475177304965e-05, Avg Loss : 0.2943\n",
            "Epoch: 1, Step : 200, LR : 1.1436170212765957e-05, Avg Loss : 0.2168\n",
            "Epoch: 1, Step : 210, LR : 1.1258865248226952e-05, Avg Loss : 0.2424\n",
            "Epoch: 1, Step : 220, LR : 1.1081560283687944e-05, Avg Loss : 0.2744\n",
            "Epoch: 1, Step : 230, LR : 1.0904255319148938e-05, Avg Loss : 0.2230\n",
            "Epoch: 1, Step : 240, LR : 1.072695035460993e-05, Avg Loss : 0.2461\n",
            "Epoch: 1, Step : 250, LR : 1.0549645390070923e-05, Avg Loss : 0.2184\n",
            "Epoch: 1, Step : 260, LR : 1.0372340425531916e-05, Avg Loss : 0.2299\n",
            "Epoch: 1, Step : 270, LR : 1.0195035460992908e-05, Avg Loss : 0.3401\n",
            "Epoch: 1, Step : 280, LR : 1.00177304964539e-05, Avg Loss : 0.2770\n",
            "Epoch 1 Total Mean Loss : 0.2585\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Epoch 1 Valid Loss : 0.2793 Valid Acc : 89.77\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "Saving epoch 1 checkpoint at ./model.ckpt.1\n",
            "*****Epoch 2 Train Start*****\n",
            "Epoch: 2, Step : 10, LR : 9.804964539007093e-06, Avg Loss : 0.1569\n",
            "Epoch: 2, Step : 20, LR : 9.627659574468086e-06, Avg Loss : 0.1774\n",
            "Epoch: 2, Step : 30, LR : 9.450354609929078e-06, Avg Loss : 0.1831\n",
            "Epoch: 2, Step : 40, LR : 9.273049645390073e-06, Avg Loss : 0.1336\n",
            "Epoch: 2, Step : 50, LR : 9.095744680851063e-06, Avg Loss : 0.1949\n",
            "Epoch: 2, Step : 60, LR : 8.918439716312058e-06, Avg Loss : 0.1974\n",
            "Epoch: 2, Step : 70, LR : 8.74113475177305e-06, Avg Loss : 0.2232\n",
            "Epoch: 2, Step : 80, LR : 8.563829787234044e-06, Avg Loss : 0.1573\n",
            "Epoch: 2, Step : 90, LR : 8.386524822695035e-06, Avg Loss : 0.2138\n",
            "Epoch: 2, Step : 100, LR : 8.20921985815603e-06, Avg Loss : 0.1864\n",
            "Epoch: 2, Step : 110, LR : 8.031914893617022e-06, Avg Loss : 0.1538\n",
            "Epoch: 2, Step : 120, LR : 7.854609929078016e-06, Avg Loss : 0.1575\n",
            "Epoch: 2, Step : 130, LR : 7.677304964539007e-06, Avg Loss : 0.1964\n",
            "Epoch: 2, Step : 140, LR : 7.500000000000001e-06, Avg Loss : 0.1605\n",
            "Epoch: 2, Step : 150, LR : 7.3226950354609935e-06, Avg Loss : 0.1690\n",
            "Epoch: 2, Step : 160, LR : 7.145390070921986e-06, Avg Loss : 0.1086\n",
            "Epoch: 2, Step : 170, LR : 6.968085106382979e-06, Avg Loss : 0.1816\n",
            "Epoch: 2, Step : 180, LR : 6.790780141843972e-06, Avg Loss : 0.1736\n",
            "Epoch: 2, Step : 190, LR : 6.613475177304965e-06, Avg Loss : 0.1783\n",
            "Epoch: 2, Step : 200, LR : 6.436170212765958e-06, Avg Loss : 0.1964\n",
            "Epoch: 2, Step : 210, LR : 6.258865248226951e-06, Avg Loss : 0.1437\n",
            "Epoch: 2, Step : 220, LR : 6.081560283687944e-06, Avg Loss : 0.2100\n",
            "Epoch: 2, Step : 230, LR : 5.904255319148937e-06, Avg Loss : 0.1561\n",
            "Epoch: 2, Step : 240, LR : 5.7269503546099295e-06, Avg Loss : 0.2478\n",
            "Epoch: 2, Step : 250, LR : 5.549645390070923e-06, Avg Loss : 0.1568\n",
            "Epoch: 2, Step : 260, LR : 5.372340425531915e-06, Avg Loss : 0.2170\n",
            "Epoch: 2, Step : 270, LR : 5.195035460992908e-06, Avg Loss : 0.1643\n",
            "Epoch: 2, Step : 280, LR : 5.017730496453901e-06, Avg Loss : 0.1464\n",
            "Epoch 2 Total Mean Loss : 0.1790\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Epoch 2 Valid Loss : 0.3184 Valid Acc : 89.26\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "Saving epoch 2 checkpoint at ./model.ckpt.2\n",
            "*****Epoch 3 Train Start*****\n",
            "Epoch: 3, Step : 10, LR : 4.804964539007093e-06, Avg Loss : 0.1708\n",
            "Epoch: 3, Step : 20, LR : 4.6276595744680855e-06, Avg Loss : 0.1558\n",
            "Epoch: 3, Step : 30, LR : 4.450354609929078e-06, Avg Loss : 0.1535\n",
            "Epoch: 3, Step : 40, LR : 4.273049645390071e-06, Avg Loss : 0.1149\n",
            "Epoch: 3, Step : 50, LR : 4.095744680851064e-06, Avg Loss : 0.0983\n",
            "Epoch: 3, Step : 60, LR : 3.918439716312057e-06, Avg Loss : 0.1108\n",
            "Epoch: 3, Step : 70, LR : 3.74113475177305e-06, Avg Loss : 0.0954\n",
            "Epoch: 3, Step : 80, LR : 3.5638297872340426e-06, Avg Loss : 0.1061\n",
            "Epoch: 3, Step : 90, LR : 3.386524822695036e-06, Avg Loss : 0.1216\n",
            "Epoch: 3, Step : 100, LR : 3.2092198581560285e-06, Avg Loss : 0.1103\n",
            "Epoch: 3, Step : 110, LR : 3.031914893617022e-06, Avg Loss : 0.1266\n",
            "Epoch: 3, Step : 120, LR : 2.8546099290780144e-06, Avg Loss : 0.1346\n",
            "Epoch: 3, Step : 130, LR : 2.6773049645390077e-06, Avg Loss : 0.1382\n",
            "Epoch: 3, Step : 140, LR : 2.5e-06, Avg Loss : 0.1654\n",
            "Epoch: 3, Step : 150, LR : 2.322695035460993e-06, Avg Loss : 0.0882\n",
            "Epoch: 3, Step : 160, LR : 2.145390070921986e-06, Avg Loss : 0.1077\n",
            "Epoch: 3, Step : 170, LR : 1.968085106382979e-06, Avg Loss : 0.1237\n",
            "Epoch: 3, Step : 180, LR : 1.790780141843972e-06, Avg Loss : 0.2125\n",
            "Epoch: 3, Step : 190, LR : 1.6134751773049648e-06, Avg Loss : 0.1134\n",
            "Epoch: 3, Step : 200, LR : 1.4361702127659578e-06, Avg Loss : 0.0877\n",
            "Epoch: 3, Step : 210, LR : 1.2588652482269503e-06, Avg Loss : 0.0917\n",
            "Epoch: 3, Step : 220, LR : 1.0815602836879434e-06, Avg Loss : 0.1487\n",
            "Epoch: 3, Step : 230, LR : 9.042553191489363e-07, Avg Loss : 0.1281\n",
            "Epoch: 3, Step : 240, LR : 7.26950354609929e-07, Avg Loss : 0.1033\n",
            "Epoch: 3, Step : 250, LR : 5.496453900709221e-07, Avg Loss : 0.1820\n",
            "Epoch: 3, Step : 260, LR : 3.723404255319149e-07, Avg Loss : 0.1439\n",
            "Epoch: 3, Step : 270, LR : 1.9503546099290782e-07, Avg Loss : 0.1205\n",
            "Epoch: 3, Step : 280, LR : 1.773049645390071e-08, Avg Loss : 0.1139\n",
            "Epoch 3 Total Mean Loss : 0.1272\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Epoch 3 Valid Loss : 0.3444 Valid Acc : 89.06\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "Saving epoch 3 checkpoint at ./model.ckpt.3\n",
            "Train Completed. End Program.\n"
          ]
        }
      ],
      "source": [
        "epochs=4\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, train_dataloader, valid_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T03:27:18.246441Z",
          "start_time": "2022-02-02T03:27:18.236617Z"
        },
        "id": "vA3_vqqCXccc"
      },
      "source": [
        "### 가장 dev acc 성능이 높았던 epoch의 모델의 체크 포인트를 불러와 로드하자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:27.646150Z",
          "start_time": "2022-02-02T06:22:26.945572Z"
        },
        "id": "mvfkSff25Q3z"
      },
      "outputs": [],
      "source": [
        "# torch.load 함수 사용\n",
        "\n",
        "checkpoint = torch.load('model.ckpt.1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:36.415665Z",
          "start_time": "2022-02-02T06:22:36.407250Z"
        },
        "id": "YqcxMmTj5Q3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee07c8cb-f748-4fe6-bbe9-e068027738f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# checkpoint의 key 종류를 확인\n",
        "checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.272939Z",
          "start_time": "2022-02-02T06:22:37.010491Z"
        },
        "id": "wTvFYgNi5Q30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cb6c68-1274-4e5e-e0c8-b93c35492bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 1 epochs: 282\n"
          ]
        }
      ],
      "source": [
        "# 위에서 구현한 initializer 함수 사용하여 model, optimizer, scheduler 초기화\n",
        "\n",
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.443912Z",
          "start_time": "2022-02-02T06:22:40.274323Z"
        },
        "id": "CtR2sTW55Q30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c069ee8-ed50-4ef6-da4c-32f04a48a4b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzske7SR5Q30"
      },
      "source": [
        "### 모델 예측 함수 구현\n",
        "- test_dataloader를 입력받아 모델이 예측한 확률값 (probs)과 실제 정답 (label) 을 출력하는 `\bpredict()` 함수를 구현하자.\n",
        "- 함수 정의\n",
        "  - 입력 매개변수\n",
        "    - `model` : `CustomClassifier` 모델. logits를 반환함 \n",
        "    - `test_dataloader` : test 데이터셋의 텍스트와 레이블을 배치로 갖는 dataloader\n",
        "  - 조건\n",
        "    - `test_dataloader`는 이터레이터기 때문에 이터레이터를 순회하면서 `all_logits` 리스트에 배치 단위의 logits를 저장하고 `all_labels` 리스트에 배치 단위의 레이블 (0 또는 1 값)을 저장하라\n",
        "  - 반환값\n",
        "    - `probs`\n",
        "      - logits에 softmax 함수를 취한 확률값. (test data 개수, label 개수) shape을 가짐. \bnp.array 타입으로 데이터 타입을 변환할 것.\n",
        "    - `labels`\n",
        "      - 0 또는 1 값을 갖는 np.array. (test data 개수,) shape을 가짐."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.062229Z",
          "start_time": "2022-02-02T06:22:48.057531Z"
        },
        "id": "yQ7WiD1Oigg9"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_dataloader):\n",
        "  \"\"\"\n",
        "  test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "  \"\"\"\n",
        "\n",
        "  # model을 eval 모드로 설정 & device 할당\n",
        "  model.eval()\n",
        "  model.to(device)\n",
        "\n",
        "  all_logits = []\n",
        "  all_labels = []\n",
        "\n",
        "  for step, batch in enumerate(test_dataloader):\n",
        "    print(f\"{step}/{len(test_dataloader)}\")\n",
        "      \n",
        "    batch_input, batch_label = batch\n",
        "    \n",
        "    # batch_input을 device 할당\n",
        "    batch_input = batch_input.to(device)\n",
        "\n",
        "    # model에 batch_input을 넣어 logit 반환 & all_logits, all_labels 리스트에 값 추가 \n",
        "    with torch.no_grad(): # 추론하면서 미분 계산 없이 (그래서 CUDA 에러난거)\n",
        "      logits = model(**batch_input)\n",
        "      all_logits.append(logits)\n",
        "    \n",
        "    all_labels.extend(batch_label) #append가 아니라 extend인 이유?\n",
        "    \n",
        "  # logits 담긴 리스트 하나로?\n",
        "  all_logits = torch.cat(all_logits, dim=0) \n",
        "  # logits을 확률값으로 변환 & Tensor 타입을 numpy.array 타입으로 변환\n",
        "  probs = F.softmax(all_logits, dim=1).cpu().numpy() \n",
        "  #  Tensor 타입을 numpy.array 타입으로 변환\n",
        "  all_labels = np.array(all_labels)\n",
        "\n",
        "  return probs, all_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델이 예측한 확률값과 실제 label을 입력 받아 정확도를 출력하는 **accuracy()** 함수를 구현하자. \n",
        "- 함수 정의 \n",
        "  - 입력 매개변수 \n",
        "    - `probs` : `predict()` 함수의 반환값. 2차원의 np.array\n",
        "    - `labels` : `predict()` 함수의 반환값. 1차원의 np.array\n",
        "  - 조건\n",
        "    - `probs`의 확률값이 0.5 이상이면 1, 이하이면 0이 되도록 만든다. 모델이 예측한 레이블을 실제값(`labels`)과 비교해 예측값과 실제값이 같으면 1, 다르면 0 점수를 준다. 모든 데이터에 대해 점수의 평균값이 accuracy 값이다. \n",
        "  - 반환값 \n",
        "    - `acc` : 정확도 (Float type)"
      ],
      "metadata": {
        "id": "lOxCjZ2g6ZeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(probs, labels):\n",
        "  y_pred = np.where(probs>0.5, 1, 0)\n",
        "  return float(sum(labels == np.argmax(y_pred, axis=1))/ len(labels))"
      ],
      "metadata": {
        "id": "MyujpS_gquTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.752497Z",
          "start_time": "2022-02-02T06:22:48.652784Z"
        },
        "id": "SwkrRPAhjsXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454e6333-7616-4464-c2e9-7efc24213a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/16\n",
            "1/16\n",
            "2/16\n",
            "3/16\n",
            "4/16\n",
            "5/16\n",
            "6/16\n",
            "7/16\n",
            "8/16\n",
            "9/16\n",
            "10/16\n",
            "11/16\n",
            "12/16\n",
            "13/16\n",
            "14/16\n",
            "15/16\n"
          ]
        }
      ],
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "Hq9u6qVr3BvQ",
        "outputId": "244b2d59-0b19-4874-e9a0-f663ecb7122e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.759367Z",
          "start_time": "2022-02-02T06:24:22.753997Z"
        },
        "id": "MxDI8PRA5Q32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52a6d78-3fbd-401d-9e11-01f1f3543fc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "accuracy(probs, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mqUfkx-5Q33"
      },
      "source": [
        "### `sklearn.metrics`의 `accuracy_score`, `roc_auc_score` 함수를 이용해 정확도와 auc를 계산하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.111879Z",
          "start_time": "2022-02-02T06:24:22.760568Z"
        },
        "id": "VFWj4lcp5Q33"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV933MZI2hUl",
        "outputId": "b2d90584-6826-45d9-b43a-c4ce938d36c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9800443 , 0.01995566],\n",
              "       [0.9655425 , 0.03445748],\n",
              "       [0.12757973, 0.87242025],\n",
              "       ...,\n",
              "       [0.03151277, 0.9684872 ],\n",
              "       [0.16589667, 0.83410335],\n",
              "       [0.03070051, 0.96929955]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.116872Z",
          "start_time": "2022-02-02T06:24:23.113064Z"
        },
        "id": "p9BEe2mflTem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19b4986-0c66-4821-f340-09a0667dd5a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8629999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "roc_auc_score(labels, np.argmax(probs, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.125650Z",
          "start_time": "2022-02-02T06:24:23.117847Z"
        },
        "id": "oCl6BiPGpCPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e81d10-9623-4b1b-ebad-cf989f38f004"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "accuracy_score(labels, np.argmax(probs, axis=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[보강제출]정다현 - Week2_4_assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}